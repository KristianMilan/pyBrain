# **pyBrain**

Brief description
====
Let's start to say what this project isn't.

THIS WORK IS NOT TARGETED TO BE A HUMAN'S BRAIN IMPLEMENTATION

I'M NOT AIMING TO PRODUCE A SPEAKING UMAN BRAIN

THIS PROJECT IS TARGETED TO PRODUCE A GENERIC TEACHABLE *ARTIFICIAL INTELLIGENCE*.

This project is an example of Artificial Intelligence implementation.
It is based on personal studies about psicology and personal inspiration.

The basic idea: 
Considering a set of binary inputs, and a set of binary outputs, we have to create a data structure that for each combination on inputs can 
relate all the outputs combinations.

This data structure must allow to be *modeled* in order to provide, for a given input, the best outputs combination.
In order to achieve this we create two hidden layers that interconnect the inputs and outputs layer.

The first hidden layer is composed by a number of *neurons* that represents all the inputs configurations. 
A specific input configuration activates one specific *neuron*.

The second hidden layer is composed by a number of *neurons* that represents all the outputs configurations.
A specific *first layer neuron* can activate potentially all *second layer neurons*, but only one gets activated. 
The one that activates depends on the *strength* of its connection.

![Alt text](https://raw.githubusercontent.com/dddomodossola/pyBrain/master/res/basic_network.png "Basic network")

The information are represented by the connections in the "modelable substratus". These connections will be strengthened or weakened by some kind 
of feedback function that, considering the output effect, teaches the network.
At this point, there is about nothing of *intelligence*.

Now, suppose you want to get an output that have to be related to the previous *events* (for *event* it is intended the combination of input/output),
how to do this with the said data structure? We can provide back the previous inputs outputs as new inputs.

![Alt text](https://raw.githubusercontent.com/dddomodossola/pyBrain/master/res/memory_network.png "Memory network")

So what we have now?
The modelable substratus corresponds to a permanent memory that gets modeled by the *experience* of the network.
The inputs and outputs that are provdided back to the network, corresponds to a short time memory. This means that, an output of the network is conditioned by the previous events.
The inputs and outputs can be provided back to the network N times, in consideration of the wanted solveable sequences length of operations.

Considering that the connections in the substratus increases in complexity exponentially, this requires special implementation solutions.

A more complex network, reflects in a longer *experience* needed to teach the network.

# **feedback function**
We talked about a feedback function. This is important to model the substratus.
This function have to be related to internal properties of the system and MUST NOT be a complex function.
It's better to explain this with an example:
Suppose the network is part of an animal. 
And suppose the animal can perform operations like *walk*, *jump*, *eat*. 
The feedback function MUST NOT take care about the output provided by the animal in a specific situation. 
Insted it have to be related to an interal property of the animal, like an internal parameter such as the *healt*.
So, an input is given to the network, an output is provided to the network, a feedback is generated by an evaluation of the internal healt of the animal.
This reflects to a simplest implementation of the feedback function, allowing an auto teaching of the network.

# **network of networks**
The complexity of a *brain* can be reduced dividing the entire network in a subset of simpler networks, maybe one for each kind of sense organs, one to collect input organ networks's output...
Dividing in multiple networks reduces the learing time.

# **attention concept**
TODO - speedup learning because relates the output to the most important inputs
The attention have to be applied to a subnetwork and not to a subset of single inputs.

# **network projection**
TODO - how to plan a network structure, input and output have to provide enough information and allow enough operation in order to get the network ability...

# **the provided test**
The provided test uses Kivy 1.6 that can be downloaded here https://kivy.org/downloads/1.6.0/

# **future works**
Emulate a C. elegans worm.

Resources here:
http://www.wormatlas.org/neuronalwiring.html